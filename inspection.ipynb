{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstractor.train import get_training_batch as get_abstractor_training_batch\n",
    "from abstractor.utils import AbstractorModel, AbstractorModelRNN\n",
    "from abstractor.utils import obtain_initial_hidden_states\n",
    "from bert.utils import obtain_sentence_embeddings\n",
    "from bert.utils import obtain_word_embeddings\n",
    "from data.utils import load_training_dictionaries\n",
    "from extractor.train import get_training_batch as get_extractor_training_batch\n",
    "from extractor.utils import ExtractorModel\n",
    "from extractor.train import convert_training_dict\n",
    "from pytorch_transformers import BertModel\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from matplotlib import pyplot as plt\n",
    "from rl_connection.utils import RLModel\n",
    "from rl_connection.train import get_training_batch as get_rl_training_batch\n",
    "from rouge import Rouge\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    for x in results:\n",
    "        print(f'{x}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_training_dictionaries()\n",
    "documents, extraction_labels = convert_training_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load extractor model:\n",
    "extractor_model = ExtractorModel(bert_tokenizer, bert_model)\n",
    "extractor_model_path = \"results/models/extractor.pt\"\n",
    "extractor_model.load_state_dict(torch.load(extractor_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ext_training_loss = pickle.load(open('results/losses/extractor_training_losses.pkl', 'rb'))\n",
    "\n",
    "def get_moving_average(a, n=3) :\n",
    "    moving_average = np.cumsum(a, dtype=float)\n",
    "    moving_average[n:] = moving_average[n:] - moving_average[:-n] # Shift and subtract\n",
    "    moving_average = moving_average[n - 1:] / n\n",
    "    return moving_average\n",
    "\n",
    "\n",
    "moving_average = get_moving_average(ext_training_loss, n=100)\n",
    "plt.plot(moving_average)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings, sentence_mask = obtain_sentence_embeddings(\n",
    "    extractor_model.bert_model, \n",
    "    extractor_model.bert_tokenizer, \n",
    "    documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### PREDICTIONS: ###############\n",
      "alison wilson , 36 , ( pictured ) died after stopping to help break up a late - night street row between a man and a woman with a baby in widnes , cheshire .\n",
      "\n",
      "alison wilson , 36 , is believed to have been returning to her home in widnes , cheshire , when she spotted a disturbance between the man and the mother and baby .\n",
      "\n",
      "she was taken to whiston hospital following the incident at about 11.20 pm on saturday , march 7 , but died from her injuries six days later on march 13 .\n",
      "\n",
      "she was taken to whiston hospital following the incident at about 11.20 pm on saturday , march 7 , but died from her injuries six days later on march 13 .\n",
      "\n",
      "mrs wilson joined another passer - by in trying to break up the row in a residential street in widnes , cheshire , ( pictured ) at 11.20 pm on march 7 but suffered serious injuries after being attacked while trying to intervene .\n",
      "\n",
      "stephen duggan , 27 , of no fixed abode , was arrested in connection with the incident and remains in custody charged with two counts of wounding with intent and two counts of assault .\n",
      "\n",
      "############### TARGETS: ###############\n",
      "alison wilson , 36 , ( pictured ) died after stopping to help break up a late - night street row between a man and a woman with a baby in widnes , cheshire .\n",
      "\n",
      "alison wilson , 36 , is believed to have been returning to her home in widnes , cheshire , when she spotted a disturbance between the man and the mother and baby .\n",
      "\n",
      "ms wilson and her partner , 43 , tried to break up the row but suffered serious injuries after being attacked while trying to intervene .\n",
      "\n",
      "she was taken to whiston hospital following the incident at about 11.20 pm on saturday , march 7 , but died from her injuries six days later on march 13 .\n",
      "\n",
      "mrs wilson joined another passer - by in trying to break up the row in a residential street in widnes , cheshire , ( pictured ) at 11.20 pm on march 7 but suffered serious injuries after being attacked while trying to intervene .\n",
      "\n",
      "stephen duggan , 27 , of no fixed abode , was arrested in connection with the incident and remains in custody charged with two counts of wounding with intent and two counts of assault .\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "\n",
      "############### PREDICTIONS: ###############\n",
      "during the fight , the 33 - year - old kicked her between her legs , leading her to require hospital treatment .\n",
      "\n",
      "womaniser : dj malachi halstead has been jailed for attacking his girlfriend when she complained about him cheating on her ; these photographs show him posing in nightclubs with a number of different women .\n",
      "\n",
      "newport crown court heard that halstead , who djs under the names ' madman ' and ' madskie ' , admits that ' fidelity is not his strongest quality ' .\n",
      "\n",
      "the dj , who has the word ' madman ' tattooed across his back , has previously been spent time in jail for a variety of offences .\n",
      "\n",
      "############### TARGETS: ###############\n",
      "during the fight , the 33 - year - old kicked her between her legs , leading her to require hospital treatment .\n",
      "\n",
      "womaniser : dj malachi halstead has been jailed for attacking his girlfriend when she complained about him cheating on her ; these photographs show him posing in nightclubs with a number of different women .\n",
      "\n",
      "newport crown court heard that halstead , who djs under the names ' madman ' and ' madskie ' , admits that ' fidelity is not his strongest quality ' .\n",
      "\n",
      "the dj , who has the word ' madman ' tattooed across his back , has previously been spent time in jail for a variety of offences .\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "\n",
      "############### PREDICTIONS: ###############\n",
      "a new paper published by a group of software engineers suggests that the internet search giant may be preparing to change the algorithms it uses to scour the web .\n",
      "\n",
      "google may be about to change the way it delivers search results to users by ranking results by accuracy .\n",
      "\n",
      "android pay users will then be able to upload credit card or debit card information to a single secure location but use it to pay for items across apps .\n",
      "\n",
      "they use a system they have called knowledge - based trust , which pulls facts from many pages and then jointly estimates the correctness and accuracy of these .\n",
      "\n",
      "the list of the top five gossip sites above currently rank in the top 15 per cent of search results but google researchers say that using their new algorithm these will be religated to the bottom half of search results .\n",
      "\n",
      "############### TARGETS: ###############\n",
      "a new paper published by a group of software engineers suggests that the internet search giant may be preparing to change the algorithms it uses to scour the web .\n",
      "\n",
      "currently web searches are ranked by , among other things , the number of incoming links to a page to help google 's search bots determine the quality of the link .\n",
      "\n",
      "google researchers have developed a new algorithm that looks for facts and inaccuracies on web pages .\n",
      "\n",
      "they use a system they have called knowledge - based trust , which pulls facts from many pages and then jointly estimates the correctness and accuracy of these .\n",
      "\n",
      "the list of the top five gossip sites above currently rank in the top 15 per cent of search results but google researchers say that using their new algorithm these will be religated to the bottom half of search results .\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "\n",
      "############### PREDICTIONS: ###############\n",
      "amy goldberg , 57 , was charged with battery on a person 65 years or older after the incident .\n",
      "\n",
      "a boca raton woman is accused of smearing dog poop on her elderly neighbor 's face to get revenge following argument .\n",
      "\n",
      "the smearing suspect 's neighbor was walking her dog when the animal defecated on the lawn in front of goldberg 's home at the woodfield country club in boca raton , according to an arrest report .\n",
      "\n",
      "if convicted , goldberg could be sentenced to a minimum of three years in prison and be forced to pay fines of up to $ 10,000 .\n",
      "\n",
      "############### TARGETS: ###############\n",
      "amy goldberg , 57 , was charged with battery on a person 65 years or older after the incident .\n",
      "\n",
      "amy goldberg is accused of putting it on her 67 - year - old neighbor 's face and arms last week .\n",
      "\n",
      "the smearing suspect 's neighbor was walking her dog when the animal defecated on the lawn in front of goldberg 's home at the woodfield country club in boca raton , according to an arrest report .\n",
      "\n",
      "if convicted , goldberg could be sentenced to a minimum of three years in prison and be forced to pay fines of up to $ 10,000 .\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samp_embeddings, samp_masks, samp_labels, samp_indicies = get_extractor_training_batch(\n",
    "    sentence_embeddings,\n",
    "    sentence_mask,\n",
    "    extraction_labels,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "\n",
    "doc_lengths = torch.sum(samp_masks, dim=1)\n",
    "samp_embeddings = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "    samp_embeddings,\n",
    "    lengths=doc_lengths,\n",
    "    batch_first=True,\n",
    "    enforce_sorted=False\n",
    ")\n",
    "\n",
    "\n",
    "# Predict probability of extraction per sentence\n",
    "extraction_probabilities, extraction_mask = extractor_model(samp_embeddings, samp_masks, samp_labels)\n",
    "\n",
    "for batch_idx, ext_probs in enumerate(extraction_probabilities):\n",
    "    doc = documents[samp_indicies[batch_idx]]\n",
    "    \n",
    "#     ext_sent_indicies = torch.tensor(range(extraction_mask[batch_idx].sum()))\n",
    "    ext_sent_indicies = torch.argmax(ext_probs, dim=-1)[:extraction_mask[batch_idx].sum()]\n",
    "\n",
    "    predicted_ext_sents = np.array(doc)[ext_sent_indicies]\n",
    "    target_ext_sents = np.array(doc)[torch.where(samp_labels[batch_idx])]\n",
    "    \n",
    "    \n",
    "    print(\"############### PREDICTIONS: ###############\")\n",
    "    print_results(predicted_ext_sents)\n",
    "    print(\"############### TARGETS: ###############\")\n",
    "    print_results(target_ext_sents)\n",
    "    print('--------------------------------------------------------')\n",
    "    print('--------------------------------------------------------')\n",
    "    print('--------------------------------------------------------\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_training_dictionaries()\n",
    "documents, ext_labs = convert_training_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-08d29545db52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Obtain distribution amongst sentences to extract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_first_sent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mis_first_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/summarization/extractor/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_embeddings, sent_mask, extraction_indicator, use_init_embedding)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mext_indicator_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mext_indicator_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0msrc_sent_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msent_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0muse_init_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_init_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         )\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/summarization/extractor/utils.py\u001b[0m in \u001b[0;36mobtain_extraction_probabilities\u001b[0;34m(self, h, ext_indicator_dict, src_sent_mask, use_init_embedding)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mh_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mtemp_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_indicator_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_init_embedding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mtemp_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_sent_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "batch_size = 4 \n",
    "\n",
    "batch_state, mask, samp_labels, samp_indicies = get_extractor_training_batch(\n",
    "    sentence_embeddings,\n",
    "    sentence_mask,\n",
    "    ext_labs,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "n_label_sents = samp_labels.sum(-1)\n",
    "# Obtain maximum number of sentences to extract\n",
    "if n_label_sents is None:\n",
    "    n_doc_sents = mask.sum(dim=1)\n",
    "    batch_max_n_ext_sents = torch.tensor([self.max_n_ext_sents] * batch_size)\n",
    "    batch_max_n_ext_sents = torch.min(batch_max_n_ext_sents.float(), n_doc_sents)\n",
    "else:\n",
    "    batch_max_n_ext_sents = n_label_sents\n",
    "\n",
    "# Create variables to stop extraction loop\n",
    "max_n_ext_sents = batch_max_n_ext_sents.max()  # Maximum number of sentences to extract\n",
    "n_actions = batch_state.shape[1]\n",
    "stop_action_idx = n_actions - 1  # Previously appended stop_action embedding\n",
    "is_stop_action = torch.zeros(batch_size).bool()\n",
    "\n",
    "doc_lengths = torch.sum(samp_masks, dim=1)\n",
    "batch_state = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "    batch_state,\n",
    "    lengths=doc_lengths,\n",
    "    batch_first=True,\n",
    "    enforce_sorted=False\n",
    ")\n",
    "\n",
    "# Extraction loop\n",
    "action_indicies, ext_sents, action_dists, stop_action_list = list(), list(), list(), list()\n",
    "n_ext_sents = 0\n",
    "is_first_sent = True\n",
    "extraction_labels = None\n",
    "while True:\n",
    "    # Obtain distribution amongst sentences to extract\n",
    "    if is_first_sent:\n",
    "        action_probs, __ = extractor_model.forward(batch_state, mask)\n",
    "        is_first_sent = False\n",
    "    else:\n",
    "        action_probs, action_mask = extractor_model.forward(\n",
    "            sent_embeddings=batch_state,\n",
    "            sent_mask=mask,\n",
    "            extraction_indicator=extraction_labels,\n",
    "            use_init_embedding=False\n",
    "        )\n",
    "\n",
    "#     # Don't select already extracted sentences\n",
    "#     # Todo: Fix this, something is wrong with the shapes.\n",
    "#     if action_indicies:\n",
    "#         indicies_to_ignore = torch.cat(action_indicies).T\n",
    "#         extraction_mask = torch.ones(action_probs.shape)\n",
    "#         batch_idx = [[x] for x in range(batch_size)]\n",
    "#         extraction_mask[batch_idx, 0, indicies_to_ignore] = 0\n",
    "#         action_probs = action_probs * extraction_mask\n",
    "\n",
    "#     # For probability distribution\n",
    "#     action_dist = self.convert_to_dist(action_probs)\n",
    "#     action_dist = Categorical(action_dist)\n",
    "\n",
    "#     # Sample sentence to extract\n",
    "#     action_idx = action_dist.sample().T\n",
    "\n",
    "#     # Form extraction_labels Todo: rename and use action_indicies instead\n",
    "#     extraction_labels = torch.zeros(batch_state.shape[:2])\n",
    "#     extraction_labels[torch.arange(batch_state.shape[0]), action_idx] = 1\n",
    "\n",
    "#     # index of sentence to extract\n",
    "#     ext_sent = batched_index_select(batch_state, 1, action_idx)\n",
    "\n",
    "#     # Collect\n",
    "#     action_dists.append(action_dist)\n",
    "#     ext_sents.append(ext_sent)\n",
    "#     action_indicies.append(action_idx)\n",
    "\n",
    "#     # Track number of sentences extracted from article\n",
    "#     n_ext_sents = n_ext_sents + 1\n",
    "\n",
    "#     # Check to see if should stop extracting sentences\n",
    "#     is_stop_action = is_stop_action | (action_idx >= stop_action_idx)\n",
    "#     stop_action_list.append(is_stop_action)\n",
    "#     all_samples_stop = torch.sum(is_stop_action) >= batch_size\n",
    "#     is_long_enough = n_ext_sents >= max_n_ext_sents\n",
    "#     if all_samples_stop or is_long_enough:\n",
    "#         break\n",
    "    break\n",
    "# action_indicies = torch.stack(action_indicies).T.squeeze(1)\n",
    "# n_ext_sents = (~torch.stack(stop_action_list).squeeze(1).T).sum(dim=1)\n",
    "# ext_sents = torch.stack(ext_sents).transpose(0, 1).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "abstractor_model = AbstractorModelRNN(bert_tokenizer, bert_model)\n",
    "abstractor_model_path = \"results/models/abstractor.pt\"\n",
    "abstractor_model.load_state_dict(torch.load(abstractor_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_documents, target_summaries = get_abstractor_training_batch(data, 1)\n",
    "\n",
    "# Obtain embeddings\n",
    "source_document_embeddings, source_mask, source_tokens = obtain_word_embeddings(\n",
    "    abstractor_model.bert_model, abstractor_model.bert_tokenizer, source_documents, static_embeddings=False\n",
    ")\n",
    "target_summary_embeddings, target_mask, target_tokens = obtain_word_embeddings(\n",
    "    abstractor_model.bert_model, abstractor_model.bert_tokenizer, target_summaries, static_embeddings=True\n",
    ")\n",
    "\n",
    "print(source_documents)\n",
    "print()\n",
    "print(target_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = abstractor_model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=0\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [abstractor_model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"------------\")\n",
    "\n",
    "\n",
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = abstractor_model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=1\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [abstractor_model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_model = RLModel(extractor_model, abstractor_model)\n",
    "rl_model.load_state_dict(torch.load(\"results/models/rl.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_documents, target_summaries = get_rl_training_batch(data, batch_size=1)\n",
    "\n",
    "# Obtain embeddings\n",
    "source_sentence_embeddings, source_mask = obtain_sentence_embeddings(\n",
    "    rl_model.extractor_model.bert_model,\n",
    "    rl_model.extractor_model.bert_tokenizer,\n",
    "    source_documents\n",
    ")\n",
    "stop_action_index = source_sentence_embeddings.shape[1]\n",
    "target_summary_embeddings, target_mask, target_tokens = obtain_word_embeddings(\n",
    "    rl_model.abstractor_model.bert_model,\n",
    "    rl_model.abstractor_model.bert_tokenizer,\n",
    "    target_summaries,\n",
    "    static_embeddings=True\n",
    ")\n",
    "\n",
    "# Run trajectory\n",
    "actions, log_probs, entropys, values, n_ext_sents = rl_model.sample_actions(\n",
    "    source_sentence_embeddings,\n",
    "    source_mask\n",
    ")\n",
    "\n",
    "# Obtain abstracted sentence from abstractor\n",
    "predicted_tokens, word_probabilities = rl_model.create_abstracted_sentences(\n",
    "    actions,\n",
    "    source_documents,\n",
    "    n_ext_sents=n_ext_sents,\n",
    "    teacher_forcing_pct=0,\n",
    "    target_summary_embeddings=target_summary_embeddings\n",
    ")\n",
    "\n",
    "# Look at extractions\n",
    "for art_idx, doc_sentences in enumerate(actions):\n",
    "    for sent_idx in doc_sentences[:-1]:\n",
    "        print(source_documents[art_idx][sent_idx])\n",
    "        print()\n",
    "    print(\"\\n\\n-------\\n\\n\")\n",
    "    \n",
    "# Look at abstractions\n",
    "for predicted_abstraction in predicted_tokens:\n",
    "    solution = list()\n",
    "    for token in predicted_abstraction:\n",
    "        solution.append(rl_model.abstractor_model.bert_tokenizer.ids_to_tokens[int(token)])\n",
    "    print(\" \".join(solution))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "print(\"-------\\n\\n\")\n",
    "target_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from extractor.train import convert_training_dict\n",
    "from bert.utils import obtain_sentence_embeddings\n",
    "from data.utils import load_training_dictionaries, create_training_dictionaries\n",
    "\n",
    "create_training_dictionaries(output_data_path='data/validation_data/', input_file_path='data/validation_data/raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dictionaries = load_training_dictionaries(input_file=\"data/validation_data/data_dictionaries.pkl\")\n",
    "documents, extraction_labels = convert_training_dict(training_dictionaries)\n",
    "\n",
    "obtain_sentence_embeddings(\n",
    "    bert_model, \n",
    "    bert_tokenizer, \n",
    "    documents, \n",
    "    data_dir='data/extractor_data/validation_embeddings/{}', \n",
    "    load_old=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2, 3, 4], [4,5,6,7]]).float()\n",
    "b = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "    a,\n",
    "    lengths=[2, 4],\n",
    "    batch_first=True,\n",
    "    enforce_sorted=False\n",
    ")\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "softmax(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    [1, 2, 4],\n",
    "    [4, 7, 7]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserStandardizer:\n",
    "    \"\"\"Implements standardization in a unstateful way.\"\"\"\n",
    "\n",
    "    def __init__(self, axis=1):\n",
    "        self.axis = axis\n",
    "        if axis == 0:\n",
    "            self.shape = (1, -1)\n",
    "        else:\n",
    "            self.shape = (-1, 1)\n",
    "\n",
    "    def transform(self, input_data: np.ndarray) -> np.ndarray:\n",
    "        mean = np.mean(input_data, axis=self.axis).reshape(*self.shape)\n",
    "        std = np.std(input_data, axis=self.axis, ddof=1).reshape(*self.shape)\n",
    "        print(mean)\n",
    "        print(std)\n",
    "\n",
    "        return (input_data - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = UserStandardizer(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.33333333]\n",
      " [6.        ]]\n",
      "[[1.52752523]\n",
      " [1.73205081]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.87287156, -0.21821789,  1.09108945],\n",
       "       [-1.15470054,  0.57735027,  0.57735027]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std.transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarization-project",
   "language": "python",
   "name": "summarization-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
