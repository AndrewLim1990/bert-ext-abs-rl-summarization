{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstractor.train import get_training_batch\n",
    "from abstractor.utils import AbstractorModel\n",
    "from abstractor.utils import obtain_initial_hidden_states\n",
    "from bert.utils import obtain_sentence_embeddings\n",
    "from bert.utils import obtain_word_embeddings\n",
    "from data.utils import load_training_dictionaries\n",
    "from extractor.utils import ExtractorModel\n",
    "from pytorch_transformers import BertModel\n",
    "from pytorch_transformers import BertTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data:\n",
    "model = AbstractorModel()\n",
    "model_path = \"results/models/abstractor.pt\"\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_training_dictionaries()\n",
    "documents, extraction_labels = get_training_batch(data, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['that may sound like an esoteric adage , but when zully broussard selflessly decided to give one of her kidneys to a stranger , her generosity paired up with big data . it resulted in six patients receiving transplants .', 'that changed when a computer programmer named david jacobs received a kidney transplant . he had been waiting on a deceased donor list , when a live donor came along -- someone nice enough to give away a kidney to a stranger .']\n",
      "\n",
      "['\" weasels will go for anything that looks like food -- they \\'ve got a high metabolism and they \\'ve got to eat a lot , \" she said . \" it does n\\'t surprise me that a weasel took a punt -- i \\'ve seen a photo of a weasel charging a group of sparrows , they \\'re very hungry animals . \"', 'weasels would not normally target green woodpeckers , pacheco said -- their predators are normally the size of a stoat or larger . but the birds are known to spend a fair amount of time on the ground pulling up worms and hunting insects .', 'the pluckiness of the weasel spawned a number of parodies on twitter , with manipulated images showing the creature in turn being ridden by russian president vladimir putin , popstar miley cyrus , football star john terry -- and even what appears to be a dog red panda dressed in a darth vader costume . ( update : twitter has now educated us on the difference between a dog and a red panda . sorry , darth ! )']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_documents, target_summaries = get_training_batch(data, 2)\n",
    "\n",
    "# Obtain embeddings\n",
    "source_document_embeddings, source_mask, source_tokens = obtain_word_embeddings(\n",
    "    model.bert_model, model.bert_tokenizer, source_documents\n",
    ")\n",
    "target_summary_embeddings, target_mask, target_tokens = obtain_word_embeddings(\n",
    "    model.bert_model, model.bert_tokenizer, target_summaries\n",
    ")\n",
    "\n",
    "for x in source_documents:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7868,  0.3158,  0.1873,  ...,  0.1196,  0.4806,  0.2568],\n",
       "         [-1.2319,  0.1560,  0.0955,  ...,  0.3285,  0.2373,  0.1838],\n",
       "         [-0.0765,  0.0044,  0.2287,  ..., -0.2080,  0.3268,  0.2944],\n",
       "         ...,\n",
       "         [-0.1307,  0.5610, -0.3290,  ...,  0.7418,  0.5953,  0.3729],\n",
       "         [-0.1307,  0.5610, -0.3290,  ...,  0.7418,  0.5953,  0.3729],\n",
       "         [-0.1307,  0.5610, -0.3290,  ...,  0.7418,  0.5953,  0.3729]],\n",
       "\n",
       "        [[-0.7868,  0.3158,  0.1873,  ...,  0.1196,  0.4806,  0.2568],\n",
       "         [-0.4989,  0.5350, -0.0610,  ...,  0.3245,  0.9572, -0.4521],\n",
       "         [-0.4652, -0.8745, -1.1583,  ...,  0.5437,  0.3467, -0.2192],\n",
       "         ...,\n",
       "         [-0.7139,  0.2176,  0.1208,  ...,  0.7653,  0.6087,  0.0047],\n",
       "         [-0.8020,  0.1763, -0.1569,  ...,  0.2405,  0.0256,  0.2617],\n",
       "         [ 0.8146,  0.0918, -0.2448,  ...,  0.1399, -0.6142, -0.4597]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zu', '##lly', 'bro', '##uss', '##ard', 'decided', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a', 'kidney', 'to', 'give', 'a']\n",
      "\n",
      "['zu', 'with', 'a', 'kidney', 'snapped', 'by', 'amateur', 'photographer', 'martin', 'le', '-', 'may', 'near', 'london', '.', '[SEP]', '-', 'may', 'near', 'london', '.', '[SEP]', '-', 'may', 'near', 'london', '.', '[SEP]', '-', 'may', 'near', 'london', '.', '[SEP]', '-', 'may', 'near', 'london', '.', '[SEP]', '-', 'may', 'near', 'london', '.', '[SEP]', '-', 'may', 'near', 'london', '.', '[SEP]', '-']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=0\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zu', '##lly', 'bro', '##uss', '##ard', 'decided', 'to', 'give', 'a', 'kidney', 'to', 'give', 'kidney', '.', '[SEP]', 'kidney', 'computer', 'program', 'helped', 'her', 'donation', 'spur', 'transplant', '##s', 'for', 'give', 'kidney', 'to', '.', '[SEP]', '-', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n",
      "\n",
      "['zu', 'kidney', 'of', 'a', 'kidney', 'wood', '##pe', '##cker', 'and', 'with', 'a', 'kidney', 'on', '-', 'back', 'has', 'le', 'viral', 'on', '-', '.', '[SEP]', 'hash', 'was', 'snapped', 'by', 'amateur', 'photographer', 'martin', 'le', '-', 'may', 'near', 'london', '.', '[SEP]', 'sparked', 'the', 'hash', '##tag', 'of', 'weasel', 'on', '##cker', 'and', 'has', 'le', 'numerous', 'me', '##mes', '.', '[SEP]', '-']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=1\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['zully broussard decided to give a kidney to a stranger .',\n",
       "  'a new computer program helped her donation spur transplants for six kidney patients .'],\n",
       " ['a photo of a green woodpecker flying with a weasel on its back has gone viral on twitter .',\n",
       "  'the image was snapped by amateur photographer martin le - may near london .',\n",
       "  'it sparked the hashtag #weaselpecker and has spawned numerous memes .']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2617,  0.0380,  0.0511,  ...,  0.1047,  0.7850, -0.2537],\n",
       "          [-1.1310, -0.7267,  0.6471,  ..., -0.1336,  1.3996,  0.7395],\n",
       "          [ 0.3222, -0.3686,  0.7603,  ..., -0.3291,  0.1432, -0.6941],\n",
       "          ...,\n",
       "          [ 0.4166, -0.3199,  0.7278,  ..., -0.7318,  0.0372, -1.3327],\n",
       "          [ 0.2818, -0.2167,  0.7193,  ..., -0.7352,  0.0445, -1.2620],\n",
       "          [ 0.5745,  0.1054,  0.4005,  ..., -0.7345,  0.0988, -1.7492]],\n",
       " \n",
       "         [[-0.1115, -0.1828, -0.4249,  ...,  0.2145,  0.5005,  0.3914],\n",
       "          [ 0.2505, -0.1153, -0.4112,  ...,  0.1827, -0.3702,  0.4494],\n",
       "          [ 0.5941, -0.2543,  0.0724,  ..., -0.0385, -0.3432,  0.4666],\n",
       "          ...,\n",
       "          [ 0.8742,  0.2570,  0.4955,  ..., -0.0061, -0.3800,  0.0748],\n",
       "          [ 0.4946,  0.2816, -0.2287,  ...,  0.0602, -0.5411, -0.3153],\n",
       "          [ 0.3065, -0.1702,  0.2163,  ...,  0.4447, -0.3457, -0.2315]]]),\n",
       " tensor([[-0.2098, -0.5410, -0.9906,  ..., -0.8945, -0.5418,  0.2921],\n",
       "         [-0.9284, -0.5976, -0.9467,  ..., -0.7569, -0.7451,  0.8098]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = torch.tensor([[  101, 16950,  9215, 22953, 17854,  4232,  2787,  2000,  2507,  1037,\n",
    "         14234,  2000,  1037,  7985,  1012,  1037,  2047,  3274,  2565,  3271,\n",
    "          2014, 13445, 12996, 22291,  2015,  2005,  2416, 14234,  5022,  1012,\n",
    "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0],\n",
    "        [  101,  1037,  6302,  1997,  1037,  2665,  3536,  5051,  9102,  3909,\n",
    "          2007,  1037, 29268,  2006,  2049,  2067,  2038,  2908, 13434,  2006,\n",
    "         10474,  1012,  1996,  3746,  2001,  5941,  2011,  5515,  8088,  3235,\n",
    "          3393,  1011,  2089,  2379,  2414,  1012,  2009, 13977,  1996, 23325,\n",
    "         15900,  1001, 29268,  5051,  9102,  1998,  2038, 18379,  3365,  2033,\n",
    "          7834,  1012,   102]])\n",
    "\n",
    "model.bert_model(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 53])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 53, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert_model(documents[0].view(1, -1))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarization-project",
   "language": "python",
   "name": "summarization-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
