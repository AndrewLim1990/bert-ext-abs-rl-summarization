{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstractor.train import get_training_batch as get_abstractor_training_batch\n",
    "from abstractor.utils import AbstractorModel, AbstractorModelRNN\n",
    "from abstractor.utils import obtain_initial_hidden_states\n",
    "from bert.utils import obtain_sentence_embeddings\n",
    "from bert.utils import obtain_word_embeddings\n",
    "from data.utils import load_training_dictionaries\n",
    "from extractor.train import get_training_batch as get_extractor_training_batch\n",
    "from extractor.utils import ExtractorModel\n",
    "from pytorch_transformers import BertModel\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from rl_connection.utils import RLModel\n",
    "from rl_connection.train import get_training_batch as get_rl_training_batch\n",
    "from rouge import Rouge\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_training_dictionaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load extractor model:\n",
    "extractor_model = ExtractorModel(bert_tokenizer, bert_model)\n",
    "extractor_model_path = \"results/models/extractor.pt\"\n",
    "extractor_model.load_state_dict(torch.load(extractor_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, extraction_labels = get_extractor_training_batch(data, batch_size=2)\n",
    "\n",
    "sentence_embeddings, mask = obtain_sentence_embeddings(\n",
    "    extractor_model.bert_model, \n",
    "    extractor_model.bert_tokenizer, \n",
    "    documents\n",
    ")\n",
    "\n",
    "# Predict probability of extraction per sentence\n",
    "extraction_probabilities = extractor_model(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> TARGET <----\n",
      "according to phil rawlins , co-primary owner and president of the new mls franchise , orlando city soccer club , \" the industry and the game itself has moved on dramatically \" in the u.s. . he believes what would equal 50 years growth in most other industries has been experienced in the first two decades of the mls .\n",
      "\n",
      "a report by forbes at the end of 2013 , meanwhile , claimed that only 10 out of 19 mls teams were profitable . and as recently as this week , mls players looked like they could be going on strike over wages and the right of players to become free agents when their contracts end .\n",
      "\n",
      "this includes promising generation adidas players who enter the mls through the draft systems before completing their college education . homegrown players from club 's development academies are also exempt as are a maximum of three designated players ( dps ) , usually stellar international names whose wages and transfer fees will be covered by club owners or sponsors .\n",
      "\n",
      "\n",
      "----> PREDICTION <----\n",
      "according to phil rawlins , co-primary owner and president of the new mls franchise , orlando city soccer club , \" the industry and the game itself has moved on dramatically \" in the u.s. . he believes what would equal 50 years growth in most other industries has been experienced in the first two decades of the mls . \n",
      "\n",
      "this includes promising generation adidas players who enter the mls through the draft systems before completing their college education . homegrown players from club 's development academies are also exempt as are a maximum of three designated players ( dps ) , usually stellar international names whose wages and transfer fees will be covered by club owners or sponsors . \n",
      "\n",
      "a report by forbes at the end of 2013 , meanwhile , claimed that only 10 out of 19 mls teams were profitable . and as recently as this week , mls players looked like they could be going on strike over wages and the right of players to become free agents when their contracts end . \n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n",
      "----> TARGET <----\n",
      "\" weasels will go for anything that looks like food -- they 've got a high metabolism and they 've got to eat a lot , \" she said . \" it does n't surprise me that a weasel took a punt -- i 've seen a photo of a weasel charging a group of sparrows , they 're very hungry animals . \"\n",
      "\n",
      "weasels would not normally target green woodpeckers , pacheco said -- their predators are normally the size of a stoat or larger . but the birds are known to spend a fair amount of time on the ground pulling up worms and hunting insects .\n",
      "\n",
      "the pluckiness of the weasel spawned a number of parodies on twitter , with manipulated images showing the creature in turn being ridden by russian president vladimir putin , popstar miley cyrus , football star john terry -- and even what appears to be a dog red panda dressed in a darth vader costume . ( update : twitter has now educated us on the difference between a dog and a red panda . sorry , darth ! )\n",
      "\n",
      "\n",
      "----> PREDICTION <----\n",
      "the pluckiness of the weasel spawned a number of parodies on twitter , with manipulated images showing the creature in turn being ridden by russian president vladimir putin , popstar miley cyrus , football star john terry -- and even what appears to be a dog red panda dressed in a darth vader costume . ( update : twitter has now educated us on the difference between a dog and a red panda . sorry , darth ! ) \n",
      "\n",
      "\" weasels will go for anything that looks like food -- they 've got a high metabolism and they 've got to eat a lot , \" she said . \" it does n't surprise me that a weasel took a punt -- i 've seen a photo of a weasel charging a group of sparrows , they 're very hungry animals . \" \n",
      "\n",
      "weasels would not normally target green woodpeckers , pacheco said -- their predators are normally the size of a stoat or larger . but the birds are known to spend a fair amount of time on the ground pulling up worms and hunting insects . \n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(documents)\n",
    "\n",
    "for sample_idx in range(n_samples):\n",
    "    n_to_extract = extraction_labels.sum(dim=1)[sample_idx].int() \n",
    "    ext_prob = extraction_probabilities[sample_idx] * mask[sample_idx]\n",
    "    ext_sent_indicies = torch.topk(ext_prob, k=n_to_extract)[1]\n",
    "    \n",
    "    targets = np.array(documents[sample_idx])[extraction_labels[sample_idx][:len(documents[sample_idx])].numpy().astype(bool)]\n",
    "    print(\"----> TARGET <----\")\n",
    "    for target in targets:\n",
    "        print(f\"{target}\\n\")\n",
    "    print()\n",
    "          \n",
    "    print(\"----> PREDICTION <----\")\n",
    "    for x in np.array(documents[sample_idx])[ext_sent_indicies]:\n",
    "        print(f\"{x} \\n\")\n",
    "    print(\"\\n\\n-------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data:\n",
    "abstractor_model = AbstractorModelRNN(bert_tokenizer, bert_model)\n",
    "abstractor_model_path = \"results/models/abstractor.pt\"\n",
    "abstractor_model.load_state_dict(torch.load(abstractor_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['that may sound like an esoteric adage , but when zully broussard selflessly decided to give one of her kidneys to a stranger , her generosity paired up with big data . it resulted in six patients receiving transplants .', 'that changed when a computer programmer named david jacobs received a kidney transplant . he had been waiting on a deceased donor list , when a live donor came along -- someone nice enough to give away a kidney to a stranger .']]\n",
      "\n",
      "[['zully broussard decided to give a kidney to a stranger .', 'a new computer program helped her donation spur transplants for six kidney patients .']]\n"
     ]
    }
   ],
   "source": [
    "source_documents, target_summaries = get_abstractor_training_batch(data, 1)\n",
    "\n",
    "# Obtain embeddings\n",
    "source_document_embeddings, source_mask, source_tokens = obtain_word_embeddings(\n",
    "    abstractor_model.bert_model, abstractor_model.bert_tokenizer, source_documents, static_embeddings=False\n",
    ")\n",
    "target_summary_embeddings, target_mask, target_tokens = obtain_word_embeddings(\n",
    "    abstractor_model.bert_model, abstractor_model.bert_tokenizer, target_summaries, static_embeddings=True\n",
    ")\n",
    "\n",
    "print(source_documents)\n",
    "print()\n",
    "print(target_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zu\n",
      "\n",
      "##lly\n",
      "\n",
      "bro\n",
      "\n",
      "##uss\n",
      "\n",
      "##ard\n",
      "\n",
      "decided\n",
      "\n",
      "to\n",
      "\n",
      "give\n",
      "\n",
      "a\n",
      "\n",
      "kidney\n",
      "\n",
      "for\n",
      "\n",
      "give\n",
      "\n",
      "a\n",
      "\n",
      "kidney\n",
      "\n",
      "for\n",
      "\n",
      "give\n",
      "\n",
      "a\n",
      "\n",
      "kidney\n",
      "\n",
      "for\n",
      "\n",
      "give\n",
      "\n",
      "for\n",
      "\n",
      "give\n",
      "\n",
      "for\n",
      "\n",
      "give\n",
      "\n",
      "for\n",
      "\n",
      "give\n",
      "\n",
      "for\n",
      "\n",
      "give\n",
      "\n",
      "for\n",
      "\n",
      "give\n",
      "\n",
      "for\n",
      "\n",
      "------------\n",
      "zu\n",
      "\n",
      "##lly\n",
      "\n",
      "bro\n",
      "\n",
      "##uss\n",
      "\n",
      "##ard\n",
      "\n",
      "decided\n",
      "\n",
      "to\n",
      "\n",
      "give\n",
      "\n",
      "a\n",
      "\n",
      "kidney\n",
      "\n",
      "for\n",
      "\n",
      "a\n",
      "\n",
      "kidney\n",
      "\n",
      ".\n",
      "\n",
      "a\n",
      "\n",
      "new\n",
      "\n",
      "computer\n",
      "\n",
      "program\n",
      "\n",
      "helped\n",
      "\n",
      "her\n",
      "\n",
      "donation\n",
      "\n",
      "spur\n",
      "\n",
      "transplant\n",
      "\n",
      "##s\n",
      "\n",
      "for\n",
      "\n",
      "six\n",
      "\n",
      "kidney\n",
      "\n",
      "patients\n",
      "\n",
      ".\n",
      "\n",
      "[SEP]\n",
      "\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = abstractor_model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=0\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [abstractor_model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"------------\")\n",
    "\n",
    "\n",
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = abstractor_model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=1\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [abstractor_model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_model = RLModel(extractor_model, abstractor_model)\n",
    "rl_model.load_state_dict(torch.load(\"results/models/rl.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_documents, target_summaries = get_rl_training_batch(data, batch_size=1)\n",
    "\n",
    "# Obtain embeddings\n",
    "source_sentence_embeddings, source_mask = obtain_sentence_embeddings(\n",
    "    rl_model.extractor_model.bert_model,\n",
    "    rl_model.extractor_model.bert_tokenizer,\n",
    "    source_documents\n",
    ")\n",
    "stop_action_index = source_sentence_embeddings.shape[1]\n",
    "target_summary_embeddings, target_mask, target_tokens = obtain_word_embeddings(\n",
    "    rl_model.abstractor_model.bert_model,\n",
    "    rl_model.abstractor_model.bert_tokenizer,\n",
    "    target_summaries,\n",
    "    static_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trajectory\n",
    "actions, log_probs, entropys, values = rl_model.sample_actions(source_sentence_embeddings, source_mask)\n",
    "\n",
    "# Obtain abstracted sentence from abstractor\n",
    "predicted_tokens, word_probabilities = rl_model.create_abstracted_sentences(\n",
    "    actions,\n",
    "    source_documents,\n",
    "    stop_action_index,\n",
    "    teacher_forcing_pct=0.0,\n",
    "    target_summary_embeddings=target_summary_embeddings\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" the significance of the altruistic donor is that it opens up possibilities for pairing compatible donors and recipients , \" said dr. steven katznelson . \" where there had been only three or four options , with the inclusion of the altruistic donor , we had 140 options to consider for matching donors and recipients . \"\n",
      "\n",
      "\" thanks for all the support and prayers , \" a comment on a facebook page in her name read . \" i know this entire journey is much bigger than all of us . i also know i 'm just the messenger . \"\n",
      "\n",
      "that donor 's kidney went to the next recipient , who was also paired with a donor , and so on . on friday , the last donor will give a kidney to someone who has been biding time on one of those deceased donor lists to complete the chain .\n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at extractions\n",
    "for art_idx, doc_sentences in enumerate(actions):\n",
    "    for sent_idx in doc_sentences[:-1]:\n",
    "        print(source_documents[art_idx][sent_idx])\n",
    "        print()\n",
    "    print(\"\\n\\n-------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zu ##lly bro ##uss ##ard decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided decided\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at abstractions\n",
    "for predicted_abstraction in predicted_tokens:\n",
    "    solution = list()\n",
    "    for token in predicted_abstraction:\n",
    "        solution.append(rl_model.abstractor_model.bert_tokenizer.ids_to_tokens[int(token)])\n",
    "    print(\" \".join(solution))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['zully broussard decided to give a kidney to a stranger .',\n",
       "  'a new computer program helped her donation spur transplants for six kidney patients .']]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarization-project",
   "language": "python",
   "name": "summarization-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
