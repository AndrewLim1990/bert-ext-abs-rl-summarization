{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstractor.train import get_training_batch as get_abstractor_training_batch\n",
    "from abstractor.utils import AbstractorModel, AbstractorModelRNN\n",
    "from abstractor.utils import obtain_initial_hidden_states\n",
    "from bert.utils import obtain_sentence_embeddings\n",
    "from bert.utils import obtain_word_embeddings\n",
    "from data.utils import load_training_dictionaries\n",
    "from extractor.train import get_training_batch as get_extractor_training_batch\n",
    "from extractor.utils import ExtractorModel\n",
    "from pytorch_transformers import BertModel\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from rl_connection.utils import RLModel\n",
    "from rl_connection.train import get_training_batch as get_rl_training_batch\n",
    "from rouge import Rouge\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_training_dictionaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load extractor model:\n",
    "extractor_model = ExtractorModel(bert_tokenizer, bert_model)\n",
    "extractor_model_path = \"results/models/extractor.pt\"\n",
    "extractor_model.load_state_dict(torch.load(extractor_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, extraction_labels = get_extractor_training_batch(data, batch_size=2)\n",
    "\n",
    "sentence_embeddings, mask = obtain_sentence_embeddings(\n",
    "    extractor_model.bert_model, \n",
    "    extractor_model.bert_tokenizer, \n",
    "    documents\n",
    ")\n",
    "\n",
    "# Predict probability of extraction per sentence\n",
    "extraction_probabilities = extractor_model(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> TARGET <----\n",
      "newtown police say cayman was last seen wearing a gray down winter jacket , black ski pants and hiking boots . he could be in the radnor - wayne area , roughly 20 miles from philadelphia , or may have purchased a train ticket to philadelphia , according to an alert posted on facebook .\n",
      "\n",
      "a message to families from the head of the shipley school , which cayman attends , read in part : \" cayman 's sister savannah is in ninth grade at shipley and his parents , farid and becky , are terrific people . they have contacted police and are aware that we are sending you this email . we hope that cayman is ok and are saying our prayers . \"\n",
      "\n",
      "\n",
      "----> PREDICTION <----\n",
      "a message to families from the head of the shipley school , which cayman attends , read in part : \" cayman 's sister savannah is in ninth grade at shipley and his parents , farid and becky , are terrific people . they have contacted police and are aware that we are sending you this email . we hope that cayman is ok and are saying our prayers . \" \n",
      "\n",
      "newtown police say cayman was last seen wearing a gray down winter jacket , black ski pants and hiking boots . he could be in the radnor - wayne area , roughly 20 miles from philadelphia , or may have purchased a train ticket to philadelphia , according to an alert posted on facebook . \n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n",
      "----> TARGET <----\n",
      "that may sound like an esoteric adage , but when zully broussard selflessly decided to give one of her kidneys to a stranger , her generosity paired up with big data . it resulted in six patients receiving transplants .\n",
      "\n",
      "that changed when a computer programmer named david jacobs received a kidney transplant . he had been waiting on a deceased donor list , when a live donor came along -- someone nice enough to give away a kidney to a stranger .\n",
      "\n",
      "\n",
      "----> PREDICTION <----\n",
      "that changed when a computer programmer named david jacobs received a kidney transplant . he had been waiting on a deceased donor list , when a live donor came along -- someone nice enough to give away a kidney to a stranger . \n",
      "\n",
      "that may sound like an esoteric adage , but when zully broussard selflessly decided to give one of her kidneys to a stranger , her generosity paired up with big data . it resulted in six patients receiving transplants . \n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(documents)\n",
    "\n",
    "for sample_idx in range(n_samples):\n",
    "    n_to_extract = extraction_labels.sum(dim=1)[sample_idx].int() \n",
    "    ext_prob = extraction_probabilities[sample_idx] * mask[sample_idx]\n",
    "    ext_sent_indicies = torch.topk(ext_prob, k=n_to_extract)[1]\n",
    "    \n",
    "    targets = np.array(documents[sample_idx])[extraction_labels[sample_idx][:len(documents[sample_idx])].numpy().astype(bool)]\n",
    "    print(\"----> TARGET <----\")\n",
    "    for target in targets:\n",
    "        print(f\"{target}\\n\")\n",
    "    print()\n",
    "          \n",
    "    print(\"----> PREDICTION <----\")\n",
    "    for x in np.array(documents[sample_idx])[ext_sent_indicies]:\n",
    "        print(f\"{x} \\n\")\n",
    "    print(\"\\n\\n-------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data:\n",
    "abstractor_model = AbstractorModelRNN(bert_tokenizer, bert_model)\n",
    "abstractor_model_path = \"results/models/abstractor.pt\"\n",
    "abstractor_model.load_state_dict(torch.load(abstractor_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['( cnn ) former vice president walter mondale was released from the mayo clinic on saturday after being admitted with influenza , hospital spokeswoman kelley luckstein said .', 'the 42nd vice president served under carter between 1977 and 1981 , and later ran for president , but lost to ronald reagan . but not before he made history by naming a woman , u.s. rep. geraldine a. ferraro of new york , as his running mate .']]\n",
      "\n",
      "[['walter mondale was released from the mayo clinic on saturday , hospital spokeswoman said .', 'the former vice president , 87 , was treated for cold and flu symptoms .']]\n"
     ]
    }
   ],
   "source": [
    "source_documents, target_summaries = get_abstractor_training_batch(data, 1)\n",
    "\n",
    "# Obtain embeddings\n",
    "source_document_embeddings, source_mask, source_tokens = obtain_word_embeddings(\n",
    "    abstractor_model.bert_model, abstractor_model.bert_tokenizer, source_documents, static_embeddings=False\n",
    ")\n",
    "target_summary_embeddings, target_mask, target_tokens = obtain_word_embeddings(\n",
    "    abstractor_model.bert_model, abstractor_model.bert_tokenizer, target_summaries, static_embeddings=True\n",
    ")\n",
    "\n",
    "print(source_documents)\n",
    "print()\n",
    "print(target_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walter\n",
      "\n",
      "walter\n",
      "\n",
      "walter\n",
      "\n",
      "mon\n",
      "\n",
      "##dale\n",
      "\n",
      "was\n",
      "\n",
      "released\n",
      "\n",
      "from\n",
      "\n",
      "the\n",
      "\n",
      "mayo\n",
      "\n",
      "clinic\n",
      "\n",
      "on\n",
      "\n",
      "saturday\n",
      "\n",
      "spoke\n",
      "\n",
      "##sw\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "------------\n",
      "walter\n",
      "\n",
      "walter\n",
      "\n",
      "##dale\n",
      "\n",
      "was\n",
      "\n",
      "released\n",
      "\n",
      "from\n",
      "\n",
      "the\n",
      "\n",
      "mayo\n",
      "\n",
      "clinic\n",
      "\n",
      "on\n",
      "\n",
      "saturday\n",
      "\n",
      "spoke\n",
      "\n",
      "hospital\n",
      "\n",
      "spoke\n",
      "\n",
      "##sw\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "said\n",
      "\n",
      "the\n",
      "\n",
      "former\n",
      "\n",
      "president\n",
      "\n",
      "president\n",
      "\n",
      ",\n",
      "\n",
      ",\n",
      "\n",
      "was\n",
      "\n",
      "was\n",
      "\n",
      ",\n",
      "\n",
      ",\n",
      "\n",
      "cold\n",
      "\n",
      "and\n",
      "\n",
      "flu\n",
      "\n",
      "symptoms\n",
      "\n",
      ".\n",
      "\n",
      "[SEP]\n",
      "\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = abstractor_model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=0\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [abstractor_model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"------------\")\n",
    "\n",
    "\n",
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = abstractor_model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=1\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [abstractor_model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_model = RLModel(extractor_model, abstractor_model)\n",
    "rl_model.load_state_dict(torch.load(\"results/models/rl.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_documents, target_summaries = get_rl_training_batch(data, batch_size=1)\n",
    "\n",
    "# Obtain embeddings\n",
    "source_sentence_embeddings, source_mask = obtain_sentence_embeddings(\n",
    "    rl_model.extractor_model.bert_model,\n",
    "    rl_model.extractor_model.bert_tokenizer,\n",
    "    source_documents\n",
    ")\n",
    "stop_action_index = source_sentence_embeddings.shape[1]\n",
    "target_summary_embeddings, target_mask, target_tokens = obtain_word_embeddings(\n",
    "    rl_model.abstractor_model.bert_model,\n",
    "    rl_model.abstractor_model.bert_tokenizer,\n",
    "    target_summaries,\n",
    "    static_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have size 4 at dimension 0, but got size 1 for argument #2 'batch2' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d723828f603f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m actions, log_probs, entropys, values, n_ext_sents = rl_model.sample_actions(\n\u001b[1;32m      3\u001b[0m     \u001b[0msource_sentence_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msource_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/summarization/rl_connection/utils.py\u001b[0m in \u001b[0;36msample_actions\u001b[0;34m(self, state, mask)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ext_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/summarization/rl_connection/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, mask, n_label_sents)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_label_sents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0maction_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_indicies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ext_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_label_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_indicies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ext_sents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/summarization/rl_connection/utils.py\u001b[0m in \u001b[0;36mcritic_layer\u001b[0;34m(self, batch_state, batch_mask, batch_extracted_sents)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_ext_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# Obtain context (attention weighted document embeddings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, 1, n_doc_sents)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# assign low attention to things to mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mattention_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, 1, n_doc_sents)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have size 4 at dimension 0, but got size 1 for argument #2 'batch2' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "# Run trajectory\n",
    "actions, log_probs, entropys, values, n_ext_sents = rl_model.sample_actions(\n",
    "    source_sentence_embeddings,\n",
    "    source_mask\n",
    ")\n",
    "\n",
    "# Obtain abstracted sentence from abstractor\n",
    "predicted_tokens, word_probabilities = rl_model.create_abstracted_sentences(\n",
    "    actions,\n",
    "    source_documents,\n",
    "    n_ext_sents=n_ext_sents,\n",
    "    teacher_forcing_pct=0.0,\n",
    "    target_summary_embeddings=target_summary_embeddings\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before continuing his round with a dropped ball , the four - time major winner launched the 3 - iron used to play the offending shot into the water as well .\n",
      "\n",
      "but when rory mcilroy pulled his second shot on the eighth hole of the wgc cadillac championship into a lake friday , he might as well have been channeling the much loved adam sandler character .\n",
      "\n",
      "but when rory mcilroy pulled his second shot on the eighth hole of the wgc cadillac championship into a lake friday , he might as well have been channeling the much loved adam sandler character .\n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n",
      "mondale , 87 , was diagnosed after he went to the hospital for a routine checkup following a fever , former president jimmy carter said friday .\n",
      "\n",
      "( cnn ) former vice president walter mondale was released from the mayo clinic on saturday after being admitted with influenza , hospital spokeswoman kelley luckstein said .\n",
      "\n",
      "the 42nd vice president served under carter between 1977 and 1981 , and later ran for president , but lost to ronald reagan . but not before he made history by naming a woman , u.s. rep. geraldine a. ferraro of new york , as his running mate .\n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at extractions\n",
    "for art_idx, doc_sentences in enumerate(actions):\n",
    "    for sent_idx in doc_sentences[:-1]:\n",
    "        print(source_documents[art_idx][sent_idx])\n",
    "        print()\n",
    "    print(\"\\n\\n-------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##ib into ##ib of ##eum mc ##il at ##gc cadillac the reportedly the reportedly the reportedly the reportedly the reportedly go he ang northern irish ##man frustrated after pulling water hazard ##m grade grade grade\n",
      "\n",
      "\n",
      "\n",
      "man suburban boston boston boston boston was , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at abstractions\n",
    "for predicted_abstraction in predicted_tokens:\n",
    "    solution = list()\n",
    "    for token in predicted_abstraction:\n",
    "        solution.append(rl_model.abstractor_model.bert_tokenizer.ids_to_tokens[int(token)])\n",
    "    print(\" \".join(solution))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['rory mcilroy throws club into water at wgc cadillac championship .',\n",
       "  'northern irishman frustrated after pulling shot into water hazard .'],\n",
       " ['walter mondale was released from the mayo clinic on saturday , hospital spokeswoman said .',\n",
       "  'the former vice president , 87 , was treated for cold and flu symptoms .']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarization-project",
   "language": "python",
   "name": "summarization-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
