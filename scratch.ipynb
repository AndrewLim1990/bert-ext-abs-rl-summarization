{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstractor.train import get_training_batch as get_abstractor_training_batch\n",
    "from abstractor.utils import AbstractorModel, AbstractorModelRNN\n",
    "from abstractor.utils import obtain_initial_hidden_states\n",
    "from bert.utils import obtain_sentence_embeddings\n",
    "from bert.utils import obtain_word_embeddings\n",
    "from data.utils import load_training_dictionaries\n",
    "from extractor.train import get_training_batch as get_extractor_training_batch\n",
    "from extractor.utils import ExtractorModel\n",
    "from pytorch_transformers import BertModel\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from rl_connection.utils import RLModel\n",
    "from rl_connection.train import get_training_batch as get_rl_training_batch\n",
    "from rouge import Rouge\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_training_dictionaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load extractor model:\n",
    "extractor_model = ExtractorModel(bert_tokenizer, bert_model)\n",
    "extractor_model_path = \"results/models/extractor.pt\"\n",
    "extractor_model.load_state_dict(torch.load(extractor_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, extraction_labels = get_extractor_training_batch(data, batch_size=2)\n",
    "\n",
    "sentence_embeddings, mask = obtain_sentence_embeddings(\n",
    "    extractor_model.bert_model, \n",
    "    extractor_model.bert_tokenizer, \n",
    "    documents\n",
    ")\n",
    "\n",
    "# Predict probability of extraction per sentence\n",
    "extraction_probabilities = extractor_model(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> TARGET <----\n",
      "\" weasels will go for anything that looks like food -- they 've got a high metabolism and they 've got to eat a lot , \" she said . \" it does n't surprise me that a weasel took a punt -- i 've seen a photo of a weasel charging a group of sparrows , they 're very hungry animals . \"\n",
      "\n",
      "weasels would not normally target green woodpeckers , pacheco said -- their predators are normally the size of a stoat or larger . but the birds are known to spend a fair amount of time on the ground pulling up worms and hunting insects .\n",
      "\n",
      "the pluckiness of the weasel spawned a number of parodies on twitter , with manipulated images showing the creature in turn being ridden by russian president vladimir putin , popstar miley cyrus , football star john terry -- and even what appears to be a dog red panda dressed in a darth vader costume . ( update : twitter has now educated us on the difference between a dog and a red panda . sorry , darth ! )\n",
      "\n",
      "\n",
      "----> PREDICTION <----\n",
      "the pluckiness of the weasel spawned a number of parodies on twitter , with manipulated images showing the creature in turn being ridden by russian president vladimir putin , popstar miley cyrus , football star john terry -- and even what appears to be a dog red panda dressed in a darth vader costume . ( update : twitter has now educated us on the difference between a dog and a red panda . sorry , darth ! ) \n",
      "\n",
      "\" weasels will go for anything that looks like food -- they 've got a high metabolism and they 've got to eat a lot , \" she said . \" it does n't surprise me that a weasel took a punt -- i 've seen a photo of a weasel charging a group of sparrows , they 're very hungry animals . \" \n",
      "\n",
      "weasels would not normally target green woodpeckers , pacheco said -- their predators are normally the size of a stoat or larger . but the birds are known to spend a fair amount of time on the ground pulling up worms and hunting insects . \n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n",
      "----> TARGET <----\n",
      "( cnn ) my vote for father of the year goes to curt schilling . the former major league baseball pitcher recently fired off a series of fastballs and mowed down a group of twitter trolls who made the mistake of tweeting vulgar and sexually - explicit comments about schilling 's teenage daughter .\n",
      "\n",
      "finally , it 's worth reminding everyone that freedom of expression does not mean freedom from rules , standards , and expectations that should guide your behavior . there are things you do n't say . there are boundaries , ways that we expect you to behave so you do n't terrorize other people or bring shame upon yourself , your friends , and your family . if you do n't have social skills , you do n't belong on social media .\n",
      "\n",
      "\n",
      "----> PREDICTION <----\n",
      "finally , it 's worth reminding everyone that freedom of expression does not mean freedom from rules , standards , and expectations that should guide your behavior . there are things you do n't say . there are boundaries , ways that we expect you to behave so you do n't terrorize other people or bring shame upon yourself , your friends , and your family . if you do n't have social skills , you do n't belong on social media . \n",
      "\n",
      "( cnn ) my vote for father of the year goes to curt schilling . the former major league baseball pitcher recently fired off a series of fastballs and mowed down a group of twitter trolls who made the mistake of tweeting vulgar and sexually - explicit comments about schilling 's teenage daughter . \n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(documents)\n",
    "\n",
    "for sample_idx in range(n_samples):\n",
    "    n_to_extract = extraction_labels.sum(dim=1)[sample_idx].int() \n",
    "    ext_prob = extraction_probabilities[sample_idx] * mask[sample_idx]\n",
    "    ext_sent_indicies = torch.topk(ext_prob, k=n_to_extract)[1]\n",
    "    \n",
    "    targets = np.array(documents[sample_idx])[extraction_labels[sample_idx][:len(documents[sample_idx])].numpy().astype(bool)]\n",
    "    print(\"----> TARGET <----\")\n",
    "    for target in targets:\n",
    "        print(f\"{target}\\n\")\n",
    "    print()\n",
    "          \n",
    "    print(\"----> PREDICTION <----\")\n",
    "    for x in np.array(documents[sample_idx])[ext_sent_indicies]:\n",
    "        print(f\"{x} \\n\")\n",
    "    print(\"\\n\\n-------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data:\n",
    "abstractor_model = AbstractorModelRNN(bert_tokenizer, bert_model)\n",
    "abstractor_model_path = \"results/models/abstractor.pt\"\n",
    "abstractor_model.load_state_dict(torch.load(abstractor_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['one french citizen , one belgian and three malians were killed in the attack in the capital of bamako , said gabriel toure , director of a local hospital .', 'a north african jihadist group , al - murabitun , claimed responsibility for the attack , according to mauritanian news agency al akhbar . the purported claim came in an audio message in which the group said it carried out the attack in retaliation for the killing of one of its leaders , al akhbar said .', '\" al - murabitun may be considered a regional competitor to al - qaeda in the islamic maghreb ( aqim ) , \" according to the jamestown foundation , a washington - based research and analysis firm . the u.s. state department said in january that al - murabitun is a \" newly - formed \" militant group that has presence in northern mali .']]\n",
      "\n",
      "[['a jihadist group claims responsibility in an audio recording , news agency reports .', 'the malian government calls the shooting a \" terrorist act \"', 'one french citizen , one belgian and three malians are killed .']]\n"
     ]
    }
   ],
   "source": [
    "source_documents, target_summaries = get_abstractor_training_batch(data, 1)\n",
    "\n",
    "# Obtain embeddings\n",
    "source_document_embeddings, source_mask, source_tokens = obtain_word_embeddings(\n",
    "    abstractor_model.bert_model, abstractor_model.bert_tokenizer, source_documents, static_embeddings=False\n",
    ")\n",
    "target_summary_embeddings, target_mask, target_tokens = obtain_word_embeddings(\n",
    "    abstractor_model.bert_model, abstractor_model.bert_tokenizer, target_summaries, static_embeddings=True\n",
    ")\n",
    "\n",
    "print(source_documents)\n",
    "print()\n",
    "print(target_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##ist\n",
      "\n",
      "group\n",
      "\n",
      "claims\n",
      "\n",
      "responsibility\n",
      "\n",
      "in\n",
      "\n",
      "an\n",
      "\n",
      "audio\n",
      "\n",
      "recording\n",
      "\n",
      ",\n",
      "\n",
      "the\n",
      "\n",
      "mali\n",
      "\n",
      "##an\n",
      "\n",
      "government\n",
      "\n",
      "calls\n",
      "\n",
      "the\n",
      "\n",
      "shooting\n",
      "\n",
      "a\n",
      "\n",
      "\"\n",
      "\n",
      "terrorist\n",
      "\n",
      "one\n",
      "\n",
      "french\n",
      "\n",
      "citizen\n",
      "\n",
      ",\n",
      "\n",
      "one\n",
      "\n",
      "belgian\n",
      "\n",
      "and\n",
      "\n",
      "three\n",
      "\n",
      "mali\n",
      "\n",
      "##ans\n",
      "\n",
      "are\n",
      "\n",
      "killed\n",
      "\n",
      ".\n",
      "\n",
      "[SEP]\n",
      "\n",
      "three\n",
      "\n",
      "killed\n",
      "\n",
      ".\n",
      "\n",
      "[SEP]\n",
      "\n",
      "three\n",
      "\n",
      "killed\n",
      "\n",
      ".\n",
      "\n",
      "[SEP]\n",
      "\n",
      "three\n",
      "\n",
      "------------\n",
      "##ist\n",
      "\n",
      "jihad\n",
      "\n",
      "##ist\n",
      "\n",
      "group\n",
      "\n",
      "claims\n",
      "\n",
      "responsibility\n",
      "\n",
      "in\n",
      "\n",
      "an\n",
      "\n",
      "audio\n",
      "\n",
      "recording\n",
      "\n",
      ",\n",
      "\n",
      "the\n",
      "\n",
      "agency\n",
      "\n",
      "reports\n",
      "\n",
      ".\n",
      "\n",
      "the\n",
      "\n",
      "mali\n",
      "\n",
      "##an\n",
      "\n",
      "government\n",
      "\n",
      "calls\n",
      "\n",
      "the\n",
      "\n",
      "shooting\n",
      "\n",
      "a\n",
      "\n",
      "\"\n",
      "\n",
      "terrorist\n",
      "\n",
      "one\n",
      "\n",
      "\"\n",
      "\n",
      "one\n",
      "\n",
      "french\n",
      "\n",
      "citizen\n",
      "\n",
      ",\n",
      "\n",
      "one\n",
      "\n",
      "belgian\n",
      "\n",
      "and\n",
      "\n",
      "three\n",
      "\n",
      "mali\n",
      "\n",
      "##ans\n",
      "\n",
      "are\n",
      "\n",
      "killed\n",
      "\n",
      ".\n",
      "\n",
      "[SEP]\n",
      "\n",
      "three\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = abstractor_model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=0\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [abstractor_model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"------------\")\n",
    "\n",
    "\n",
    "# Obtain extraction probability for each word in vocabulary\n",
    "extraction_probabilities, teacher_forcing = abstractor_model(\n",
    "    source_document_embeddings,\n",
    "    target_summary_embeddings,\n",
    "    teacher_forcing_pct=1\n",
    ")  # (batch_size, n_target_words, vocab_size)\n",
    "\n",
    "vals, predicted_idx = torch.topk((extraction_probabilities), k=1, dim=2)\n",
    "\n",
    "for x in [abstractor_model.bert_tokenizer.convert_ids_to_tokens(p) for p in predicted_idx.squeeze().tolist()]:\n",
    "    print(f\"{x}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_model = RLModel(extractor_model, abstractor_model)\n",
    "rl_model.load_state_dict(torch.load(\"results/models/rl.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_documents, target_summaries = get_rl_training_batch(data, batch_size=1)\n",
    "\n",
    "# Obtain embeddings\n",
    "source_sentence_embeddings, source_mask = obtain_sentence_embeddings(\n",
    "    rl_model.extractor_model.bert_model,\n",
    "    rl_model.extractor_model.bert_tokenizer,\n",
    "    source_documents\n",
    ")\n",
    "stop_action_index = source_sentence_embeddings.shape[1]\n",
    "target_summary_embeddings, target_mask, target_tokens = obtain_word_embeddings(\n",
    "    rl_model.abstractor_model.bert_model,\n",
    "    rl_model.abstractor_model.bert_tokenizer,\n",
    "    target_summaries,\n",
    "    static_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trajectory\n",
    "actions, log_probs, entropys, values, n_ext_sents = rl_model.sample_actions(\n",
    "    source_sentence_embeddings,\n",
    "    source_mask\n",
    ")\n",
    "\n",
    "# Obtain abstracted sentence from abstractor\n",
    "predicted_tokens, word_probabilities = rl_model.create_abstracted_sentences(\n",
    "    actions,\n",
    "    source_documents,\n",
    "    n_ext_sents=n_ext_sents,\n",
    "    teacher_forcing_pct=0,\n",
    "    target_summary_embeddings=target_summary_embeddings\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this includes promising generation adidas players who enter the mls through the draft systems before completing their college education . homegrown players from club 's development academies are also exempt as are a maximum of three designated players ( dps ) , usually stellar international names whose wages and transfer fees will be covered by club owners or sponsors .\n",
      "\n",
      "according to phil rawlins , co-primary owner and president of the new mls franchise , orlando city soccer club , \" the industry and the game itself has moved on dramatically \" in the u.s. . he believes what would equal 50 years growth in most other industries has been experienced in the first two decades of the mls .\n",
      "\n",
      "this weekend 60,000 fans are expected to witness orlando city 's opening weekend fixture against new york city , another new club making their mls bow . world cup winners kaka and david villa will turn out for orlando and new york city respectively .\n",
      "\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at extractions\n",
    "for art_idx, doc_sentences in enumerate(actions):\n",
    "    for sent_idx in doc_sentences[:-1]:\n",
    "        print(source_documents[art_idx][sent_idx])\n",
    "        print()\n",
    "    print(\"\\n\\n-------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but ##dale ##dale ##dale ##dale ##dale ##dale ##dale ##dale ##dale ##dale ##dale ##dale released released from but was the was the minutes but ##mis later but ##mis later but ##mis later but ##mis\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at abstractions\n",
    "for predicted_abstraction in predicted_tokens:\n",
    "    solution = list()\n",
    "    for token in predicted_abstraction:\n",
    "        solution.append(rl_model.abstractor_model.bert_tokenizer.ids_to_tokens[int(token)])\n",
    "    print(\" \".join(solution))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the 20th mls season begins this weekend .',\n",
       "  'league has changed dramatically since its inception in 1996 .',\n",
       "  'some question whether rules regarding salary caps and transfers need to change .']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarization-project",
   "language": "python",
   "name": "summarization-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
